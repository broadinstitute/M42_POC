# Databricks notebook source
# MAGIC %md
# MAGIC ### This pipeline loads the parquet files that were generated by GATK and placed in Blob storage and creates a new table in the RAW Zone
# MAGIC
# MAGIC This is the RAW data that will live in the Datalake RAW zone
# MAGIC
# MAGIC ##### NOTE: this notebook requires DBR 14.3 LTS
# MAGIC

# COMMAND ----------


# notebook variables

# Blob storage access
#sasToken = "sp=racwdli&st=2024-03-20T13:55:27Z&se=2024-03-26T21:55:27Z&spr=https&sv=2022-11-02&sr=c&sig=KWq0eo0FN%2BD%2F4vg%2BQIgAm8AGNxspFinKf0gPP8Zq8iA%3D"
sasToken = "sp=racwl&st=2024-04-10T13:38:18Z&se=2024-05-01T21:38:18Z&spr=https&sv=2022-11-02&sr=c&sig=KRG052bJ6jPgkbcJPWeYKqXNNqjhH2dQkf5YDA1WH8A%3D"

storageAccountName = "gvcfparquet"
storageAccountAccessKey = "none"
blobContainerName = "parquet-files"  

# vat slices
raw_input_file_path = "3k_vat_slices/3K_sample_temp_export_location/"
# table names (these are the output tables from this notebook)
raw_table_name = "vat_slices_v0"
clustered_raw_table_name = "vat_slices_v0_clustered"

source_files = f"/mnt/data/{raw_input_file_path}/"


# COMMAND ----------

# MAGIC %md
# MAGIC #### First, setup a connector to the Blob storage
# MAGIC

# COMMAND ----------


# umount the blob storage
if any(mount.mountPoint == "/mnt/data/" for mount in dbutils.fs.mounts()):
  dbutils.fs.unmount("/mnt/data")

# mount the blob storage as /mnt/data
mountPoint = "/mnt/data/"
if not any(mount.mountPoint == mountPoint for mount in dbutils.fs.mounts()):
  try:
    dbutils.fs.mount(
      source = "wasbs://{}@{}.blob.core.windows.net".format(blobContainerName, storageAccountName),
      mount_point = mountPoint,
      #extra_configs = {'fs.azure.account.key.' + storageAccountName + '.blob.core.windows.net': storageAccountAccessKey}
      extra_configs = {'fs.azure.sas.' + blobContainerName + '.' + storageAccountName + '.blob.core.windows.net': sasToken}
    )
    print("mount succeeded!")
  except Exception as e:
    print("mount exception", e) 
else: 
  print("Error: mount point exists")

# list the files we just mounted
df = spark.createDataFrame(dbutils.fs.ls(source_files))
display(df)

# COMMAND ----------

# MAGIC %md
# MAGIC #### Process all parquet files in this folder
# MAGIC
# MAGIC This will create a table (or dataset) from the parquet files located at the raw_input_file_path

# COMMAND ----------

df = spark.read.parquet(source_files)
#display(df)

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Save dataframe as a Table 
# MAGIC
# MAGIC This will save this dataframe to a permanent table that is cataloged in the Unity Data Catalog  
# MAGIC - A summary of the table can be provided
# MAGIC - columns are described
# MAGIC - comments can be added for each column
# MAGIC - Permmissions can be set for who can access/update this table
# MAGIC - lineage will be created (if we created this table as a join of two tables for example, it will which columns came from which table)
# MAGIC - etc

# COMMAND ----------

print(raw_table_name)

# COMMAND ----------


#spark.sql(f"DROP TABLE IF EXISTS {raw_table_name}")
first_columns = ["clinvar_classification", "gene_symbol", "consequence"]
rest_columns = [col for col in df.columns if col not in first_columns]
select_columns = first_columns + rest_columns

# df = df.select("clinvar_classification", "gene_symbol", "consequence", "* except(clinvar_classification, gene_symbol, consequence)")
df = df.select(*select_columns)

df.write.saveAsTable(raw_table_name)

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Cluster the table 
# MAGIC Configure liquid clustering on the **location** column, then OPTIMIZE it to perform the clustering 

# COMMAND ----------



spark.sql(f"DROP TABLE IF EXISTS {clustered_raw_table_name}") 

df = spark.read.table(raw_table_name)

# liquid cluster it by location
df.writeTo(clustered_raw_table_name).using("delta").clusterBy("clinvar_classification").clusterBy("gene_symbol").create()

# now optimize it
spark.sql(f"OPTIMIZE {clustered_raw_table_name}")


# COMMAND ----------

# MAGIC %md
# MAGIC

# COMMAND ----------

display(df)

# COMMAND ----------

# MAGIC %sql
# MAGIC --select clinvar_classification, count(*) from vat_slices_v0 group by clinvar_classification
# MAGIC select gene_symbol, count(*) from vat_slices_v0 group by gene_symbol

# COMMAND ----------

# MAGIC %sql
# MAGIC --select clinvar_classification, count(*) from vat_slices_v0 group by clinvar_classification
# MAGIC select gene_symbol, count(*) from vat_slices_clustered_v0 group by gene_symbol

# COMMAND ----------

# MAGIC %sql
# MAGIC --select clinvar_classification, count(*) from vat_slices_v0 group by clinvar_classification
# MAGIC select gene_symbol, count(*) from vat_slices_v0_clustered group by gene_symbol
# MAGIC
# MAGIC

# COMMAND ----------

# MAGIC %sql
# MAGIC /** Give me all sample IDs with pathogenic (according to ClinVar) variants in MODY genes that have GQ>20 and depth >20.
# MAGIC */
# MAGIC WITH variants as (
# MAGIC   SELECT DISTINCT vid, contig, position, ref_allele, alt_allele, gvs_all_sc
# MAGIC   FROM `vat_slices_v0` 
# MAGIC   WHERE 
# MAGIC   is_canonical_transcript = TRUE
# MAGIC   AND ARRAY_TO_STRING(clinvar_classification, '.') LIKE '%athogenic%'
# MAGIC   AND ARRAY_TO_STRING(clinvar_classification, '.') NOT LIKE '%benign%'
# MAGIC   AND gene_symbol IN ('ABCC8', 'APPL1', 'BLK','CEL','GCK','HNF1A','HNF1B','HNF4A','INS','KCNJ11','KLF11','NEUROD1','PAX4','PDX1')
# MAGIC ) 
# MAGIC
# MAGIC SELECT DISTINCT si.sample_name
# MAGIC   FROM variants, `aou-genomics-curation-prod.aou_wgs_fullref_v2.alt_allele` as aa
# MAGIC   JOIN `aou-genomics-curation-prod.aou_wgs_fullref_v2.sample_info` AS si ON aa.sample_id = si.sample_id
# MAGIC   WHERE
# MAGIC     variants.ref_allele = aa.ref AND
# MAGIC     variants.alt_allele = aa.allele AND            
# MAGIC     (CASE SPLIT(variants.contig, 'r')[OFFSET(1)]
# MAGIC                   WHEN 'X' THEN 23
# MAGIC                   WHEN 'Y' THEN 24
# MAGIC                   ELSE CAST(SPLIT(variants.contig, 'r')[OFFSET(1)] AS int64) END) * 1000000000000 + variants.position  = aa.location
# MAGIC     AND si.withdrawn is null
# MAGIC     AND si.is_control is false
# MAGIC     AND aa.call_GQ >= 20
# MAGIC     AND (aa.ref_ad + aa.ad) > 20

# COMMAND ----------

# MAGIC %sql
# MAGIC /** Give me all sample IDs with pathogenic (according to ClinVar) variants in MODY genes that have GQ>20 and depth >20.
# MAGIC */
# MAGIC WITH variants as (
# MAGIC   SELECT DISTINCT vid, contig, position, ref_allele, alt_allele, gvs_all_sc
# MAGIC   FROM M42_POC.default.vat_slices_v0 
# MAGIC   WHERE 
# MAGIC   is_canonical_transcript = TRUE
# MAGIC   AND concat_ws('.', clinvar_classification) LIKE '%athogenic%'
# MAGIC   AND concat_ws('.', clinvar_classification) NOT LIKE '%benign%'
# MAGIC   AND gene_symbol IN ('ABCC8', 'APPL1', 'BLK','CEL','GCK','HNF1A','HNF1B','HNF4A','INS','KCNJ11','KLF11','NEUROD1','PAX4','PDX1')
# MAGIC )
# MAGIC
# MAGIC SELECT DISTINCT aa.sample_id
# MAGIC   FROM variants, M42_POC.default.alt_allele_v3 as aa
# MAGIC --   JOIN `aou-genomics-curation-prod.aou_wgs_fullref_v2.sample_info` AS si ON aa.sample_id = si.sample_id
# MAGIC   WHERE
# MAGIC     variants.ref_allele = aa.ref AND
# MAGIC     variants.alt_allele = aa.allele AND            
# MAGIC     (CASE SPLIT(variants.contig, 'r')[1]
# MAGIC                   WHEN 'X' THEN 23
# MAGIC                   WHEN 'Y' THEN 24
# MAGIC                   ELSE CAST(SPLIT(variants.contig, 'r')[1] AS bigint) END) * 1000000000000 + variants.position  = aa.location
# MAGIC     -- AND si.withdrawn is null
# MAGIC     -- AND si.is_control is false
# MAGIC     AND aa.call_GQ >= 20
# MAGIC     AND (aa.ref_ad + aa.ad) > 20

# COMMAND ----------

# MAGIC %sql
# MAGIC /** Give me all sample IDs with pathogenic (according to ClinVar) variants in MODY genes that have GQ>20 and depth >20.
# MAGIC */
# MAGIC WITH variants as (
# MAGIC   SELECT DISTINCT vid, contig, position, ref_allele, alt_allele, gvs_all_sc
# MAGIC   FROM M42_POC.default.vat_slices_clustered_v0 
# MAGIC   WHERE 
# MAGIC   is_canonical_transcript = TRUE
# MAGIC   AND concat_ws('.', clinvar_classification) LIKE '%athogenic%'
# MAGIC   AND concat_ws('.', clinvar_classification) NOT LIKE '%benign%'
# MAGIC   AND gene_symbol IN ('ABCC8', 'APPL1', 'BLK','CEL','GCK','HNF1A','HNF1B','HNF4A','INS','KCNJ11','KLF11','NEUROD1','PAX4','PDX1')
# MAGIC )
# MAGIC
# MAGIC SELECT DISTINCT aa.sample_id
# MAGIC   FROM variants, M42_POC.default.alt_allele_v3 as aa
# MAGIC --   JOIN `aou-genomics-curation-prod.aou_wgs_fullref_v2.sample_info` AS si ON aa.sample_id = si.sample_id
# MAGIC   WHERE
# MAGIC     variants.ref_allele = aa.ref AND
# MAGIC     variants.alt_allele = aa.allele AND            
# MAGIC     (CASE SPLIT(variants.contig, 'r')[1]
# MAGIC                   WHEN 'X' THEN 23
# MAGIC                   WHEN 'Y' THEN 24
# MAGIC                   ELSE CAST(SPLIT(variants.contig, 'r')[1] AS bigint) END) * 1000000000000 + variants.position  = aa.location
# MAGIC     -- AND si.withdrawn is null
# MAGIC     -- AND si.is_control is false
# MAGIC     AND aa.call_GQ >= 20
# MAGIC     AND (aa.ref_ad + aa.ad) > 20

# COMMAND ----------

# MAGIC %sql
# MAGIC WITH variants as (
# MAGIC   SELECT DISTINCT vid, contig, position, ref_allele, alt_allele, concat_ws(', ',consequence) AS consequence_str, gvs_all_sc
# MAGIC   FROM M42_POC.default.vat_slices_clustered_v0 
# MAGIC   WHERE 
# MAGIC   is_canonical_transcript = TRUE
# MAGIC   AND gene_symbol="BRCA1"
# MAGIC   AND (
# MAGIC     SELECT COUNT(1)
# MAGIC     WHERE arrays_overlap(consequence, array("stop_gained", "blah", "mickey mouse"))
# MAGIC     --WHERE consequence IN ("stop_gained")
# MAGIC   ) > 0
# MAGIC ) 
# MAGIC
# MAGIC SELECT aa.sample_id
# MAGIC   FROM variants,  M42_POC.default.alt_allele_v3 as aa
# MAGIC   WHERE
# MAGIC     variants.ref_allele = aa.ref AND
# MAGIC     variants.alt_allele = aa.allele AND            
# MAGIC     (CASE SPLIT(variants.contig, 'r')[1]
# MAGIC                   WHEN 'X' THEN 23
# MAGIC                   WHEN 'Y' THEN 24
# MAGIC                   ELSE CAST(SPLIT(variants.contig, 'r')[1] AS bigint) END) * 1000000000000 + variants.position  = aa.location